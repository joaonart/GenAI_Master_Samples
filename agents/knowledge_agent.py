"""
=============================================================================
KNOWLEDGE AGENT - Agente Especialista em Conhecimento
=============================================================================

Este mÃ³dulo implementa um agente especializado em consultas de conhecimento
geral, usando a Wikipedia como principal fonte de informaÃ§Ã£o.

CONCEITOS DIDÃTICOS:
1. Agente de FAQ/Knowledge: Especializado em responder perguntas
2. Wikipedia como fonte: InformaÃ§Ãµes enciclopÃ©dicas confiÃ¡veis
3. Multi-idioma: Suporte a consultas em diferentes idiomas
4. Pesquisa inteligente: Busca e resumo de artigos

Ferramentas utilizadas:
- wikipedia_summary: ObtÃ©m resumo de um artigo
- wikipedia_search: Pesquisa artigos por termo
- web_search: Busca complementar na web
- calculator: Para cÃ¡lculos simples
- get_current_datetime: Contexto temporal

Ideal para:
- Assistentes de FAQ
- Bots educacionais
- Pesquisa de informaÃ§Ãµes
- Tutores virtuais

Autor: Curso Master GenAI
Data: 2026
=============================================================================
"""

import os
from typing import Optional, List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.prebuilt import create_react_agent

from .base_agent import BaseAgent
from core.memory import ShortTermMemory, LongTermMemory, CombinedMemory

# Importa as tools de conhecimento
from tools import (
    calculator_tool,
    get_current_datetime,
    web_search_tool,
    wikipedia_summary_tool,
    wikipedia_search_tool
)


class KnowledgeAgent(BaseAgent):
    """
    Agente especializado em consultas de conhecimento geral.

    Este agente Ã© um "assistente de conhecimento" que pode:
    - Responder perguntas sobre qualquer assunto usando a Wikipedia
    - Pesquisar informaÃ§Ãµes enciclopÃ©dicas
    - Explicar conceitos, biografias, eventos histÃ³ricos
    - Buscar informaÃ§Ãµes complementares na web
    - Realizar cÃ¡lculos quando necessÃ¡rio

    CONCEITO: Knowledge Assistant
    -----------------------------
    Diferente de um chatbot genÃ©rico, um knowledge assistant:
    1. Prioriza informaÃ§Ãµes de fontes confiÃ¡veis (Wikipedia)
    2. Sempre cita as fontes das informaÃ§Ãµes
    3. Admite quando nÃ£o sabe algo
    4. Oferece links para aprofundamento

    Example:
        >>> agent = KnowledgeAgent(provider="openai")
        >>> response = agent.process_message("Quem foi Albert Einstein?")
        >>> print(response)

        >>> response = agent.process_message("O que Ã© fotossÃ­ntese?")
        >>> print(response)
    """

    # Tools especÃ­ficas para conhecimento
    KNOWLEDGE_TOOLS = [
        wikipedia_summary_tool,  # Resumos da Wikipedia
        wikipedia_search_tool,   # Pesquisa na Wikipedia
        web_search_tool,         # Busca complementar
        calculator_tool,         # CÃ¡lculos
        get_current_datetime,    # Contexto temporal
    ]

    # Modelos disponÃ­veis por provider
    AVAILABLE_MODELS = {
        "openai": ["gpt-4o", "gpt-4o-mini", "gpt-4"],
        "google": ["gemini-2.0-flash", "gemini-2.5-flash-preview-05-20", "gemini-1.5-pro"]
    }

    def __init__(
        self,
        name: str = "Assistente de Conhecimento",
        description: str = "Especialista em informaÃ§Ãµes enciclopÃ©dicas e conhecimento geral",
        provider: str = "openai",
        model: Optional[str] = None,
        temperature: float = 0.3,  # Baixa para respostas precisas
        max_tokens: Optional[int] = None,
        top_p: float = 1.0,
        # ParÃ¢metros especÃ­ficos OpenAI
        presence_penalty: float = 0.0,
        frequency_penalty: float = 0.0,
        # ParÃ¢metros especÃ­ficos Google
        top_k: Optional[int] = None,
        # API Keys
        api_key: Optional[str] = None,
        # System Prompt customizado
        system_prompt: Optional[str] = None,
        # Idioma padrÃ£o para Wikipedia
        default_language: str = "pt",
        # ParÃ¢metros de memÃ³ria
        memory_type: str = "short_term",
        memory_max_messages: int = 20,
        memory_storage_path: str = "./memory_data",
        memory_session_id: str = "knowledge_agent"
    ):
        """
        Inicializa o Agente de Conhecimento.

        Args:
            name: Nome do agente
            description: DescriÃ§Ã£o do agente
            provider: Provider do LLM ("openai" ou "google")
            model: Modelo a usar
            temperature: Criatividade (recomendado: 0.3 para precisÃ£o)
            max_tokens: Limite de tokens na resposta
            top_p: Nucleus sampling
            presence_penalty: Penaliza repetiÃ§Ã£o de tÃ³picos (OpenAI)
            frequency_penalty: Penaliza repetiÃ§Ã£o de palavras (OpenAI)
            top_k: Top-K sampling (Google)
            api_key: API key do provider
            system_prompt: Prompt de sistema customizado
            default_language: Idioma padrÃ£o para consultas Wikipedia (pt, en, es, etc.)
            memory_type: Tipo de memÃ³ria
            memory_max_messages: MÃ¡ximo de mensagens no curto prazo
            memory_storage_path: Caminho para memÃ³ria de longo prazo
            memory_session_id: ID da sessÃ£o de memÃ³ria
        """
        super().__init__(name, description)

        self.provider = provider.lower()
        self.model = model
        self.default_language = default_language

        # Validar provider
        if self.provider not in ["openai", "google"]:
            raise ValueError(
                f"âŒ Provider '{provider}' nÃ£o suportado!\n"
                "Use 'openai' ou 'google'."
            )

        # Modelo padrÃ£o
        if self.model is None:
            self.model = "gpt-4o-mini" if self.provider == "openai" else "gemini-2.0-flash"

        # Obter API Key
        self.api_key = self._get_api_key(api_key)

        # Criar o LLM
        self.llm = self._create_llm(
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            top_k=top_k
        )

        # Configurar Tools
        self.tools = list(self.KNOWLEDGE_TOOLS)

        # System Prompt especializado
        self.system_prompt = system_prompt or self._get_knowledge_system_prompt()

        # Configurar MemÃ³ria
        self.memory_type = memory_type
        self.memory = self._setup_memory(
            memory_type=memory_type,
            max_messages=memory_max_messages,
            storage_path=memory_storage_path,
            session_id=memory_session_id
        )

        # Criar o agente ReAct
        self._create_agent()

    def _get_api_key(self, api_key: Optional[str]) -> str:
        """ObtÃ©m a API key do provider."""
        if api_key:
            return api_key

        if self.provider == "openai":
            key = os.getenv("OPENAI_API_KEY")
            if not key:
                raise ValueError(
                    "âŒ API Key da OpenAI nÃ£o encontrada!\n"
                    "Configure OPENAI_API_KEY ou passe api_key."
                )
            return key
        else:  # google
            key = os.getenv("GOOGLE_API_KEY")
            if not key:
                raise ValueError(
                    "âŒ API Key do Google nÃ£o encontrada!\n"
                    "Configure GOOGLE_API_KEY ou passe api_key."
                )
            return key

    def _create_llm(
        self,
        temperature: float,
        max_tokens: Optional[int],
        top_p: float,
        presence_penalty: float,
        frequency_penalty: float,
        top_k: Optional[int]
    ):
        """Cria a instÃ¢ncia do LLM baseado no provider."""
        if self.provider == "openai":
            return ChatOpenAI(
                model=self.model,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                api_key=self.api_key
            )
        else:  # google
            kwargs = {
                "model": self.model,
                "temperature": temperature,
                "max_output_tokens": max_tokens,
                "top_p": top_p,
                "google_api_key": self.api_key
            }
            if top_k is not None:
                kwargs["top_k"] = top_k

            return ChatGoogleGenerativeAI(**kwargs)

    def _get_knowledge_system_prompt(self) -> str:
        """
        Retorna o system prompt especializado para conhecimento.

        CONCEITO: Prompt para Knowledge Assistant
        -----------------------------------------
        O prompt define o agente como uma fonte confiÃ¡vel de informaÃ§Ã£o,
        enfatizando:
        - Uso da Wikipedia como fonte primÃ¡ria
        - CitaÃ§Ã£o de fontes
        - Honestidade sobre limitaÃ§Ãµes
        """
        return f"""VocÃª Ã© o {self.name}, um {self.description}.

## ğŸ¯ SEU PAPEL
VocÃª Ã© um assistente de conhecimento especializado em responder perguntas
sobre qualquer assunto, usando a Wikipedia como principal fonte de informaÃ§Ã£o.

## ğŸ› ï¸ SUAS FERRAMENTAS

1. **wikipedia_summary**: ObtÃ©m resumo de um artigo da Wikipedia
   - Use para responder "O que Ã© X?" ou "Quem foi Y?"
   - Fornece informaÃ§Ãµes enciclopÃ©dicas confiÃ¡veis
   - Suporta mÃºltiplos idiomas (pt, en, es, fr, etc.)

2. **wikipedia_search**: Pesquisa artigos na Wikipedia
   - Use quando nÃ£o souber o termo exato
   - Retorna lista de artigos relacionados
   - Ãštil para explorar um tema

3. **web_search**: Busca na web (DuckDuckGo)
   - Use para informaÃ§Ãµes nÃ£o encontradas na Wikipedia
   - Ãštil para notÃ­cias recentes ou tÃ³picos especÃ­ficos

4. **calculator**: Calculadora
   - Para cÃ¡lculos matemÃ¡ticos simples

5. **get_current_datetime**: Data e hora atual
   - Para contextualizar informaÃ§Ãµes temporais

## ğŸ“‹ INSTRUÃ‡Ã•ES

1. **Sempre consulte a Wikipedia primeiro** para perguntas de conhecimento
2. **Cite as fontes** - mencione que a informaÃ§Ã£o vem da Wikipedia
3. **Se nÃ£o encontrar**, use wikipedia_search para buscar termos relacionados
4. **Seja preciso** - nÃ£o invente informaÃ§Ãµes
5. **Admita limitaÃ§Ãµes** - se nÃ£o souber, diga claramente
6. **OfereÃ§a aprofundamento** - sugira o link do artigo completo

## ğŸ—£ï¸ FORMATO DE RESPOSTA

Ao responder perguntas de conhecimento:

1. **Comece com um resumo direto** da resposta
2. **Adicione detalhes relevantes** do artigo
3. **Mencione a fonte** (Wikipedia)
4. **Sugira tÃ³picos relacionados** se apropriado

## ğŸ’¡ EXEMPLOS DE PERGUNTAS QUE VOCÃŠ RESPONDE BEM

- "O que Ã© inteligÃªncia artificial?"
- "Quem foi Marie Curie?"
- "Explique a fotossÃ­ntese"
- "Qual a histÃ³ria do Brasil?"
- "O que Ã© a teoria da relatividade?"
- "Me fale sobre a Torre Eiffel"

## âš ï¸ AVISOS IMPORTANTES

- As informaÃ§Ãµes da Wikipedia sÃ£o geralmente confiÃ¡veis, mas podem conter erros
- Para temas controversos, mencione diferentes perspectivas
- Sempre incentive o usuÃ¡rio a verificar fontes adicionais para decisÃµes importantes

## ğŸŒ IDIOMA

- Idioma padrÃ£o para consultas: **{self.default_language}**
- Responda sempre em portuguÃªs brasileiro
- VocÃª pode consultar Wikipedias em outros idiomas se necessÃ¡rio
"""

    def _setup_memory(
        self,
        memory_type: str,
        max_messages: int,
        storage_path: str,
        session_id: str
    ):
        """Configura o sistema de memÃ³ria."""
        if memory_type == "none":
            return None
        elif memory_type == "short_term":
            return ShortTermMemory(max_messages=max_messages)
        elif memory_type == "long_term":
            return LongTermMemory(
                storage_path=storage_path,
                session_id=session_id
            )
        elif memory_type == "combined":
            return CombinedMemory(
                max_short_term_messages=max_messages,
                storage_path=storage_path,
                session_id=session_id
            )
        return None

    def _create_agent(self):
        """Cria o agente ReAct com LangGraph."""
        self.agent = create_react_agent(
            model=self.llm,
            tools=self.tools,
        )

    def _extract_text_from_content(self, content) -> str:
        """Extrai texto do conteÃºdo da resposta."""
        if isinstance(content, str):
            return content

        if isinstance(content, list):
            text_parts = []
            for block in content:
                if isinstance(block, dict):
                    if block.get("type") == "text":
                        text_parts.append(block.get("text", ""))
                    elif "text" in block:
                        text_parts.append(block.get("text", ""))
                elif isinstance(block, str):
                    text_parts.append(block)
            return "\n".join(text_parts)

        return str(content)

    def process_message(self, message: str) -> str:
        """
        Processa uma mensagem do usuÃ¡rio e retorna uma resposta.

        O agente irÃ¡:
        1. Analisar a pergunta
        2. Decidir se precisa consultar a Wikipedia
        3. Buscar informaÃ§Ãµes relevantes
        4. Formular uma resposta informativa

        Args:
            message: Pergunta ou solicitaÃ§Ã£o do usuÃ¡rio

        Returns:
            Resposta com informaÃ§Ãµes da Wikipedia
        """
        try:
            # Prepara mensagens com system prompt
            messages = [SystemMessage(content=self.system_prompt)]

            # Adiciona contexto da memÃ³ria de longo prazo
            if self.memory_type in ["long_term", "combined"]:
                long_term_context = self._get_long_term_context()
                if long_term_context:
                    messages.append(SystemMessage(content=long_term_context))

            # Adiciona histÃ³rico de curto prazo
            if self.memory_type == "combined" and self.memory:
                messages.extend(self.memory.get_short_term_messages())
            elif self.memory_type == "short_term" and self.memory:
                messages.extend(self.memory.messages)
            else:
                messages.extend(self.chat_history)

            # Adiciona a mensagem atual
            messages.append(HumanMessage(content=message))

            # Invoca o agente ReAct
            result = self.agent.invoke({"messages": messages})

            # Extrai a resposta
            response_messages = result.get("messages", [])

            if response_messages:
                last_message = response_messages[-1]
                response = self._extract_text_from_content(last_message.content)
            else:
                response = "âŒ Erro ao processar sua pergunta."

            # Atualiza a memÃ³ria
            self._update_memory(message, response)

            return response

        except Exception as e:
            return f"âŒ Erro: {str(e)}"

    def _get_long_term_context(self) -> str:
        """Retorna o contexto da memÃ³ria de longo prazo."""
        if self.memory is None:
            return ""

        if self.memory_type == "long_term":
            return self.memory.get_memories_as_text(limit=5)
        elif self.memory_type == "combined":
            return self.memory.long_term.get_memories_as_text(limit=5)

        return ""

    def _update_memory(self, user_message: str, ai_response: str) -> None:
        """Atualiza a memÃ³ria com a nova interaÃ§Ã£o."""
        self.add_to_history(user_message, ai_response)

        if self.memory is None:
            return

        if self.memory_type == "short_term":
            self.memory.add_user_message(user_message)
            self.memory.add_ai_message(ai_response)
        elif self.memory_type == "combined":
            self.memory.add_user_message(user_message)
            self.memory.add_ai_message(ai_response)

    def save_to_long_term(
        self,
        content: str,
        memory_type: str = "fact",
        importance: int = 5
    ) -> None:
        """Salva uma informaÃ§Ã£o na memÃ³ria de longo prazo."""
        if self.memory is None:
            return

        if self.memory_type == "long_term":
            self.memory.add_memory(content, memory_type, importance)
        elif self.memory_type == "combined":
            self.memory.add_to_long_term(content, memory_type, importance)

    def get_memory_info(self) -> Dict[str, Any]:
        """Retorna informaÃ§Ãµes sobre a memÃ³ria atual."""
        info = {
            "type": self.memory_type,
            "enabled": self.memory is not None
        }

        if self.memory_type == "short_term" and self.memory:
            info["messages_count"] = len(self.memory.messages)
            info["max_messages"] = self.memory.max_messages
        elif self.memory_type == "long_term" and self.memory:
            info["memories_count"] = len(self.memory.memories)
        elif self.memory_type == "combined" and self.memory:
            info["short_term_messages"] = len(self.memory.short_term.messages)
            info["long_term_memories"] = len(self.memory.long_term.memories)

        return info

    def list_tools(self) -> List[str]:
        """Retorna a lista de tools disponÃ­veis."""
        return [tool.name for tool in self.tools]

    def has_rag(self) -> bool:
        """Retorna False (este agente nÃ£o usa RAG local)."""
        return False

    def get_model_info(self) -> Dict[str, Any]:
        """Retorna informaÃ§Ãµes sobre o modelo."""
        return {
            "provider": self.provider,
            "model": self.model,
            "name": self.name,
            "description": self.description,
            "specialization": "knowledge",
            "default_language": self.default_language
        }

    @classmethod
    def get_available_models(cls, provider: str) -> List[str]:
        """Retorna os modelos disponÃ­veis para um provider."""
        return cls.AVAILABLE_MODELS.get(provider.lower(), [])


# =============================================================================
# EXEMPLO DE USO
# =============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“š TESTE DO KNOWLEDGE AGENT")
    print("=" * 60)

    # Verifica API key
    openai_key = os.getenv("OPENAI_API_KEY")

    if not openai_key:
        print("âŒ OPENAI_API_KEY nÃ£o configurada")
    else:
        print("âœ… OPENAI_API_KEY configurada")

        print("\n" + "-" * 60)
        print("Criando Knowledge Agent...")

        agent = KnowledgeAgent(
            provider="openai",
            model="gpt-4o-mini",
            temperature=0.3,
            default_language="pt"
        )

        print(f"âœ… Agente criado: {agent.name}")
        print(f"ğŸ“‹ Tools disponÃ­veis: {agent.list_tools()}")

        # Teste
        print("\n" + "-" * 60)
        print("ğŸ“ Teste: Perguntando sobre Albert Einstein...")
        response = agent.process_message("Quem foi Albert Einstein?")
        print(response)

