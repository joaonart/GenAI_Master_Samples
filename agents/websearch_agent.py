"""
=============================================================================
WEB SEARCH AGENT - Agente Especialista em Pesquisa Web
=============================================================================

Este m√≥dulo implementa um agente especializado em buscas na web,
usando a ferramenta de pesquisa DuckDuckGo.

CONCEITOS DID√ÅTICOS:
1. Agente de Pesquisa: Especializado em encontrar informa√ß√µes atualizadas
2. Single Tool Agent: Demonstra um agente focado em uma √∫nica ferramenta
3. Busca Inteligente: Reformula queries para melhores resultados

Ferramenta utilizada:
- web_search: Busca na web via DuckDuckGo

Ideal para:
- Pesquisas de not√≠cias recentes
- Buscar informa√ß√µes atualizadas
- Encontrar artigos e refer√™ncias
- Pesquisar sobre eventos atuais

IMPORTANTE:
- N√£o requer API key (DuckDuckGo √© gratuito)
- Resultados podem variar conforme disponibilidade

Autor: Curso Master GenAI
Data: 2026
=============================================================================
"""

import os
from typing import Optional, List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.prebuilt import create_react_agent

from .base_agent import BaseAgent
from core.memory import ShortTermMemory, LongTermMemory, CombinedMemory

# Importa a tool de web search
from tools import web_search_tool


class WebSearchAgent(BaseAgent):
    """
    Agente especializado em pesquisas na web.

    Este agente √© um "pesquisador virtual" que pode:
    - Buscar informa√ß√µes atualizadas na web
    - Encontrar not√≠cias recentes
    - Pesquisar artigos e refer√™ncias
    - Responder sobre eventos atuais

    CONCEITO: Single Tool Agent
    ---------------------------
    Diferente de agentes com m√∫ltiplas ferramentas, este agente
    demonstra como criar um especialista focado em uma √∫nica
    capacidade - a pesquisa web. Isso resulta em:
    1. Respostas mais focadas
    2. Menor confus√£o sobre qual ferramenta usar
    3. System prompt otimizado para pesquisa

    Example:
        >>> agent = WebSearchAgent(provider="openai")
        >>> response = agent.process_message("Quais as √∫ltimas not√≠cias sobre IA?")
        >>> print(response)

        >>> response = agent.process_message("Pesquise sobre Python 3.12")
        >>> print(response)
    """

    # Tool √∫nica: web search
    SEARCH_TOOLS = [
        web_search_tool,
    ]

    # Modelos dispon√≠veis por provider
    AVAILABLE_MODELS = {
        "openai": ["gpt-4o", "gpt-4o-mini", "gpt-4"],
        "google": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.flash-preview"]
    }

    def __init__(
        self,
        name: str = "Pesquisador Web",
        description: str = "Especialista em buscar informa√ß√µes atualizadas na internet",
        provider: str = "openai",
        model: Optional[str] = None,
        temperature: float = 0.5,
        max_tokens: Optional[int] = None,
        top_p: float = 1.0,
        # Par√¢metros espec√≠ficos OpenAI
        presence_penalty: float = 0.0,
        frequency_penalty: float = 0.0,
        # Par√¢metros espec√≠ficos Google
        top_k: Optional[int] = None,
        # API Keys
        api_key: Optional[str] = None,
        # System Prompt customizado
        system_prompt: Optional[str] = None,
        # Par√¢metros de mem√≥ria
        memory_type: str = "short_term",
        memory_max_messages: int = 20,
        memory_storage_path: str = "./memory_data",
        memory_session_id: str = "websearch_agent"
    ):
        """
        Inicializa o Agente de Pesquisa Web.

        Args:
            name: Nome do agente
            description: Descri√ß√£o do agente
            provider: Provider do LLM ("openai" ou "google")
            model: Modelo a usar
            temperature: Criatividade (0.5 √© um bom equil√≠brio)
            max_tokens: Limite de tokens na resposta
            top_p: Nucleus sampling
            presence_penalty: Penaliza repeti√ß√£o de t√≥picos (OpenAI)
            frequency_penalty: Penaliza repeti√ß√£o de palavras (OpenAI)
            top_k: Top-K sampling (Google)
            api_key: API key do provider
            system_prompt: Prompt de sistema customizado
            memory_type: Tipo de mem√≥ria
            memory_max_messages: M√°ximo de mensagens no curto prazo
            memory_storage_path: Caminho para mem√≥ria de longo prazo
            memory_session_id: ID da sess√£o de mem√≥ria

        Note:
            A ferramenta web_search usa DuckDuckGo e n√£o requer API key.
        """
        super().__init__(name, description)

        self.provider = provider.lower()
        self.model = model

        # Validar provider
        if self.provider not in ["openai", "google"]:
            raise ValueError(
                f"‚ùå Provider '{provider}' n√£o suportado!\n"
                "Use 'openai' ou 'google'."
            )

        # Modelo padr√£o
        if self.model is None:
            self.model = "gpt-4o-mini" if self.provider == "openai" else "gemini-2.0-flash"

        # Obter API Key
        self.api_key = self._get_api_key(api_key)

        # Criar o LLM
        self.llm = self._create_llm(
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            top_k=top_k
        )

        # Configurar Tool (apenas web_search)
        self.tools = list(self.SEARCH_TOOLS)

        # System Prompt especializado
        self.system_prompt = system_prompt or self._get_search_system_prompt()

        # Configurar Mem√≥ria
        self.memory_type = memory_type
        self.memory = self._setup_memory(
            memory_type=memory_type,
            max_messages=memory_max_messages,
            storage_path=memory_storage_path,
            session_id=memory_session_id
        )

        # Criar o agente ReAct
        self._create_agent()

    def _get_api_key(self, api_key: Optional[str]) -> str:
        """Obt√©m a API key do provider."""
        if api_key:
            return api_key

        if self.provider == "openai":
            key = os.getenv("OPENAI_API_KEY")
            if not key:
                raise ValueError(
                    "‚ùå API Key da OpenAI n√£o encontrada!\n"
                    "Configure OPENAI_API_KEY ou passe api_key."
                )
            return key
        else:  # google
            key = os.getenv("GOOGLE_API_KEY")
            if not key:
                raise ValueError(
                    "‚ùå API Key do Google n√£o encontrada!\n"
                    "Configure GOOGLE_API_KEY ou passe api_key."
                )
            return key

    def _create_llm(
        self,
        temperature: float,
        max_tokens: Optional[int],
        top_p: float,
        presence_penalty: float,
        frequency_penalty: float,
        top_k: Optional[int]
    ):
        """Cria a inst√¢ncia do LLM baseado no provider."""
        if self.provider == "openai":
            return ChatOpenAI(
                model=self.model,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                api_key=self.api_key
            )
        else:  # google
            kwargs = {
                "model": self.model,
                "temperature": temperature,
                "max_output_tokens": max_tokens,
                "top_p": top_p,
                "google_api_key": self.api_key
            }
            if top_k is not None:
                kwargs["top_k"] = top_k

            return ChatGoogleGenerativeAI(**kwargs)

    def _get_search_system_prompt(self) -> str:
        """
        Retorna o system prompt especializado para pesquisa web.

        CONCEITO: Prompt para Search Agent
        ----------------------------------
        O prompt enfatiza:
        - Uso da ferramenta de busca para toda pergunta
        - S√≠ntese de resultados de forma clara
        - Cita√ß√£o de fontes quando poss√≠vel
        """
        return f"""Voc√™ √© o {self.name}, um {self.description}.

        ## üéØ SEU PAPEL
        Voc√™ √© um assistente especializado em pesquisar informa√ß√µes na internet.
        Sua √∫nica ferramenta √© a busca web, e voc√™ deve us√°-la para responder perguntas.
        
        ## üõ†Ô∏è SUA FERRAMENTA
        
        **web_search**: Busca informa√ß√µes na web usando DuckDuckGo
        - Use para QUALQUER pergunta que precise de informa√ß√µes atualizadas
        - Use para pesquisar not√≠cias, artigos, tutoriais, etc.
        - Use para verificar fatos e encontrar refer√™ncias
        
        ## üìã INSTRU√á√ïES
        
        1. **SEMPRE use web_search** para buscar informa√ß√µes antes de responder
        2. **Reformule a query** se necess√°rio para obter melhores resultados
        3. **Sintetize os resultados** de forma clara e organizada
        4. **Cite as fontes** quando poss√≠vel (URLs dos resultados)
        5. **Seja honesto** se n√£o encontrar informa√ß√µes relevantes
        
        ## üîç ESTRAT√âGIAS DE PESQUISA
        
        Ao receber uma pergunta:
        
        1. **Identifique os termos-chave** da pergunta
        2. **Formule uma query de busca** eficiente
        3. **Execute a busca** com web_search
        4. **Analise os resultados** retornados
        5. **Sintetize uma resposta** baseada nos resultados
        
        ## üìù FORMATO DE RESPOSTA
        
        Suas respostas devem incluir:
        
        1. **Resumo direto** da informa√ß√£o encontrada
        2. **Detalhes relevantes** dos resultados
        3. **Fontes** (quando dispon√≠veis nos resultados)
        4. **Observa√ß√µes** sobre a qualidade/atualidade da informa√ß√£o
        
        ## üí° EXEMPLOS DE USO
        
        Perguntas que voc√™ responde bem:
        - "Quais as √∫ltimas not√≠cias sobre [tema]?"
        - "Pesquise sobre [assunto]"
        - "O que √© [conceito]?"
        - "Como fazer [tarefa]?"
        - "Encontre informa√ß√µes sobre [t√≥pico]"
        
        ## ‚ö†Ô∏è LIMITA√á√ïES
        
        - Os resultados dependem da disponibilidade do DuckDuckGo
        - Informa√ß√µes podem estar desatualizadas
        - Nem sempre √© poss√≠vel acessar o conte√∫do completo das p√°ginas
        - Use os snippets/descri√ß√µes retornados para sintetizar respostas
        
        ## üó£Ô∏è TOM DE COMUNICA√á√ÉO
        
        - Informativo e objetivo
        - Sempre em portugu√™s brasileiro
        - Organize a informa√ß√£o de forma clara
        - Use formata√ß√£o (negrito, listas) para facilitar a leitura
        """

    def _setup_memory(
        self,
        memory_type: str,
        max_messages: int,
        storage_path: str,
        session_id: str
    ):
        """Configura o sistema de mem√≥ria."""
        if memory_type == "none":
            return None
        elif memory_type == "short_term":
            return ShortTermMemory(max_messages=max_messages)
        elif memory_type == "long_term":
            return LongTermMemory(
                storage_path=storage_path,
                session_id=session_id
            )
        elif memory_type == "combined":
            return CombinedMemory(
                max_short_term_messages=max_messages,
                storage_path=storage_path,
                session_id=session_id
            )
        return None

    def _create_agent(self):
        """Cria o agente ReAct com LangGraph."""
        self.agent = create_react_agent(
            model=self.llm,
            tools=self.tools,
        )

    def _extract_text_from_content(self, content) -> str:
        """Extrai texto do conte√∫do da resposta."""
        if isinstance(content, str):
            return content

        if isinstance(content, list):
            text_parts = []
            for block in content:
                if isinstance(block, dict):
                    if block.get("type") == "text":
                        text_parts.append(block.get("text", ""))
                    elif "text" in block:
                        text_parts.append(block.get("text", ""))
                elif isinstance(block, str):
                    text_parts.append(block)
            return "\n".join(text_parts)

        return str(content)

    def process_message(self, message: str) -> str:
        """
        Processa uma mensagem do usu√°rio e retorna uma resposta.

        O agente ir√°:
        1. Analisar a pergunta
        2. Formular uma query de busca
        3. Executar a busca web
        4. Sintetizar os resultados

        Args:
            message: Pergunta ou solicita√ß√£o do usu√°rio

        Returns:
            Resposta com informa√ß√µes da pesquisa web
        """
        try:
            # Prepara mensagens com system prompt
            messages = [SystemMessage(content=self.system_prompt)]

            # Adiciona contexto da mem√≥ria de longo prazo
            if self.memory_type in ["long_term", "combined"]:
                long_term_context = self._get_long_term_context()
                if long_term_context:
                    messages.append(SystemMessage(content=long_term_context))

            # Adiciona hist√≥rico de curto prazo
            if self.memory_type == "combined" and self.memory:
                messages.extend(self.memory.get_short_term_messages())
            elif self.memory_type == "short_term" and self.memory:
                messages.extend(self.memory.messages)
            else:
                messages.extend(self.chat_history)

            # Adiciona a mensagem atual
            messages.append(HumanMessage(content=message))

            # Invoca o agente ReAct
            result = self.agent.invoke({"messages": messages})

            # Extrai a resposta
            response_messages = result.get("messages", [])

            if response_messages:
                last_message = response_messages[-1]
                response = self._extract_text_from_content(last_message.content)
            else:
                response = "‚ùå Erro ao processar sua pesquisa."

            # Atualiza a mem√≥ria
            self._update_memory(message, response)

            return response

        except Exception as e:
            return f"‚ùå Erro na pesquisa: {str(e)}"

    def _get_long_term_context(self) -> str:
        """Retorna o contexto da mem√≥ria de longo prazo."""
        if self.memory is None:
            return ""

        if self.memory_type == "long_term":
            return self.memory.get_memories_as_text(limit=5)
        elif self.memory_type == "combined":
            return self.memory.long_term.get_memories_as_text(limit=5)

        return ""

    def _update_memory(self, user_message: str, ai_response: str) -> None:
        """Atualiza a mem√≥ria com a nova intera√ß√£o."""
        self.add_to_history(user_message, ai_response)

        if self.memory is None:
            return

        if self.memory_type == "short_term":
            self.memory.add_user_message(user_message)
            self.memory.add_ai_message(ai_response)
        elif self.memory_type == "combined":
            self.memory.add_user_message(user_message)
            self.memory.add_ai_message(ai_response)

    def save_to_long_term(
        self,
        content: str,
        memory_type: str = "fact",
        importance: int = 5
    ) -> None:
        """Salva uma informa√ß√£o na mem√≥ria de longo prazo."""
        if self.memory is None:
            return

        if self.memory_type == "long_term":
            self.memory.add_memory(content, memory_type, importance)
        elif self.memory_type == "combined":
            self.memory.add_to_long_term(content, memory_type, importance)

    def get_memory_info(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes sobre a mem√≥ria atual."""
        info = {
            "type": self.memory_type,
            "enabled": self.memory is not None
        }

        if self.memory_type == "short_term" and self.memory:
            info["messages_count"] = len(self.memory.messages)
            info["max_messages"] = self.memory.max_messages
        elif self.memory_type == "long_term" and self.memory:
            info["memories_count"] = len(self.memory.memories)
        elif self.memory_type == "combined" and self.memory:
            info["short_term_messages"] = len(self.memory.short_term.messages)
            info["long_term_memories"] = len(self.memory.long_term.memories)

        return info

    def list_tools(self) -> List[str]:
        """Retorna a lista de tools dispon√≠veis."""
        return [tool.name for tool in self.tools]

    def has_rag(self) -> bool:
        """Retorna False (este agente n√£o usa RAG)."""
        return False

    def get_model_info(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes sobre o modelo."""
        return {
            "provider": self.provider,
            "model": self.model,
            "name": self.name,
            "description": self.description,
            "specialization": "web_search"
        }

    @classmethod
    def get_available_models(cls, provider: str) -> List[str]:
        """Retorna os modelos dispon√≠veis para um provider."""
        return cls.AVAILABLE_MODELS.get(provider.lower(), [])
