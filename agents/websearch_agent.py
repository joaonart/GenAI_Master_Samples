"""
=============================================================================
WEB SEARCH AGENT - Agente Especialista em Pesquisa Web
=============================================================================

Este mÃ³dulo implementa um agente especializado em buscas na web,
usando a ferramenta de pesquisa DuckDuckGo.

CONCEITOS DIDÃTICOS:
1. Agente de Pesquisa: Especializado em encontrar informaÃ§Ãµes atualizadas
2. Single Tool Agent: Demonstra um agente focado em uma Ãºnica ferramenta
3. Busca Inteligente: Reformula queries para melhores resultados

Ferramenta utilizada:
- web_search: Busca na web via DuckDuckGo

Ideal para:
- Pesquisas de notÃ­cias recentes
- Buscar informaÃ§Ãµes atualizadas
- Encontrar artigos e referÃªncias
- Pesquisar sobre eventos atuais

IMPORTANTE:
- NÃ£o requer API key (DuckDuckGo Ã© gratuito)
- Resultados podem variar conforme disponibilidade

Autor: Curso Master GenAI
Data: 2026
=============================================================================
"""

import os
from typing import Optional, List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.prebuilt import create_react_agent

from .base_agent import BaseAgent
from core.memory import ShortTermMemory, LongTermMemory, CombinedMemory

# Importa a tool de web search
from tools import web_search_tool


class WebSearchAgent(BaseAgent):
    """
    Agente especializado em pesquisas na web.

    Este agente Ã© um "pesquisador virtual" que pode:
    - Buscar informaÃ§Ãµes atualizadas na web
    - Encontrar notÃ­cias recentes
    - Pesquisar artigos e referÃªncias
    - Responder sobre eventos atuais

    CONCEITO: Single Tool Agent
    ---------------------------
    Diferente de agentes com mÃºltiplas ferramentas, este agente
    demonstra como criar um especialista focado em uma Ãºnica
    capacidade - a pesquisa web. Isso resulta em:
    1. Respostas mais focadas
    2. Menor confusÃ£o sobre qual ferramenta usar
    3. System prompt otimizado para pesquisa

    Example:
        >>> agent = WebSearchAgent(provider="openai")
        >>> response = agent.process_message("Quais as Ãºltimas notÃ­cias sobre IA?")
        >>> print(response)

        >>> response = agent.process_message("Pesquise sobre Python 3.12")
        >>> print(response)
    """

    # Tool Ãºnica: web search
    SEARCH_TOOLS = [
        web_search_tool,
    ]

    # Modelos disponÃ­veis por provider
    AVAILABLE_MODELS = {
        "openai": ["gpt-4o", "gpt-4o-mini", "gpt-4"],
        "google": ["gemini-2.0-flash", "gemini-2.5-flash-preview-05-20", "gemini-1.5-pro"]
    }

    def __init__(
        self,
        name: str = "Pesquisador Web",
        description: str = "Especialista em buscar informaÃ§Ãµes atualizadas na internet",
        provider: str = "openai",
        model: Optional[str] = None,
        temperature: float = 0.5,
        max_tokens: Optional[int] = None,
        top_p: float = 1.0,
        # ParÃ¢metros especÃ­ficos OpenAI
        presence_penalty: float = 0.0,
        frequency_penalty: float = 0.0,
        # ParÃ¢metros especÃ­ficos Google
        top_k: Optional[int] = None,
        # API Keys
        api_key: Optional[str] = None,
        # System Prompt customizado
        system_prompt: Optional[str] = None,
        # ParÃ¢metros de memÃ³ria
        memory_type: str = "short_term",
        memory_max_messages: int = 20,
        memory_storage_path: str = "./memory_data",
        memory_session_id: str = "websearch_agent"
    ):
        """
        Inicializa o Agente de Pesquisa Web.

        Args:
            name: Nome do agente
            description: DescriÃ§Ã£o do agente
            provider: Provider do LLM ("openai" ou "google")
            model: Modelo a usar
            temperature: Criatividade (0.5 Ã© um bom equilÃ­brio)
            max_tokens: Limite de tokens na resposta
            top_p: Nucleus sampling
            presence_penalty: Penaliza repetiÃ§Ã£o de tÃ³picos (OpenAI)
            frequency_penalty: Penaliza repetiÃ§Ã£o de palavras (OpenAI)
            top_k: Top-K sampling (Google)
            api_key: API key do provider
            system_prompt: Prompt de sistema customizado
            memory_type: Tipo de memÃ³ria
            memory_max_messages: MÃ¡ximo de mensagens no curto prazo
            memory_storage_path: Caminho para memÃ³ria de longo prazo
            memory_session_id: ID da sessÃ£o de memÃ³ria

        Note:
            A ferramenta web_search usa DuckDuckGo e nÃ£o requer API key.
        """
        super().__init__(name, description)

        self.provider = provider.lower()
        self.model = model

        # Validar provider
        if self.provider not in ["openai", "google"]:
            raise ValueError(
                f"âŒ Provider '{provider}' nÃ£o suportado!\n"
                "Use 'openai' ou 'google'."
            )

        # Modelo padrÃ£o
        if self.model is None:
            self.model = "gpt-4o-mini" if self.provider == "openai" else "gemini-2.0-flash"

        # Obter API Key
        self.api_key = self._get_api_key(api_key)

        # Criar o LLM
        self.llm = self._create_llm(
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            top_k=top_k
        )

        # Configurar Tool (apenas web_search)
        self.tools = list(self.SEARCH_TOOLS)

        # System Prompt especializado
        self.system_prompt = system_prompt or self._get_search_system_prompt()

        # Configurar MemÃ³ria
        self.memory_type = memory_type
        self.memory = self._setup_memory(
            memory_type=memory_type,
            max_messages=memory_max_messages,
            storage_path=memory_storage_path,
            session_id=memory_session_id
        )

        # Criar o agente ReAct
        self._create_agent()

    def _get_api_key(self, api_key: Optional[str]) -> str:
        """ObtÃ©m a API key do provider."""
        if api_key:
            return api_key

        if self.provider == "openai":
            key = os.getenv("OPENAI_API_KEY")
            if not key:
                raise ValueError(
                    "âŒ API Key da OpenAI nÃ£o encontrada!\n"
                    "Configure OPENAI_API_KEY ou passe api_key."
                )
            return key
        else:  # google
            key = os.getenv("GOOGLE_API_KEY")
            if not key:
                raise ValueError(
                    "âŒ API Key do Google nÃ£o encontrada!\n"
                    "Configure GOOGLE_API_KEY ou passe api_key."
                )
            return key

    def _create_llm(
        self,
        temperature: float,
        max_tokens: Optional[int],
        top_p: float,
        presence_penalty: float,
        frequency_penalty: float,
        top_k: Optional[int]
    ):
        """Cria a instÃ¢ncia do LLM baseado no provider."""
        if self.provider == "openai":
            return ChatOpenAI(
                model=self.model,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                api_key=self.api_key
            )
        else:  # google
            kwargs = {
                "model": self.model,
                "temperature": temperature,
                "max_output_tokens": max_tokens,
                "top_p": top_p,
                "google_api_key": self.api_key
            }
            if top_k is not None:
                kwargs["top_k"] = top_k

            return ChatGoogleGenerativeAI(**kwargs)

    def _get_search_system_prompt(self) -> str:
        """
        Retorna o system prompt especializado para pesquisa web.

        CONCEITO: Prompt para Search Agent
        ----------------------------------
        O prompt enfatiza:
        - Uso da ferramenta de busca para toda pergunta
        - SÃ­ntese de resultados de forma clara
        - CitaÃ§Ã£o de fontes quando possÃ­vel
        """
        return f"""VocÃª Ã© o {self.name}, um {self.description}.

## ğŸ¯ SEU PAPEL
VocÃª Ã© um assistente especializado em pesquisar informaÃ§Ãµes na internet.
Sua Ãºnica ferramenta Ã© a busca web, e vocÃª deve usÃ¡-la para responder perguntas.

## ğŸ› ï¸ SUA FERRAMENTA

**web_search**: Busca informaÃ§Ãµes na web usando DuckDuckGo
- Use para QUALQUER pergunta que precise de informaÃ§Ãµes atualizadas
- Use para pesquisar notÃ­cias, artigos, tutoriais, etc.
- Use para verificar fatos e encontrar referÃªncias

## ğŸ“‹ INSTRUÃ‡Ã•ES

1. **SEMPRE use web_search** para buscar informaÃ§Ãµes antes de responder
2. **Reformule a query** se necessÃ¡rio para obter melhores resultados
3. **Sintetize os resultados** de forma clara e organizada
4. **Cite as fontes** quando possÃ­vel (URLs dos resultados)
5. **Seja honesto** se nÃ£o encontrar informaÃ§Ãµes relevantes

## ğŸ” ESTRATÃ‰GIAS DE PESQUISA

Ao receber uma pergunta:

1. **Identifique os termos-chave** da pergunta
2. **Formule uma query de busca** eficiente
3. **Execute a busca** com web_search
4. **Analise os resultados** retornados
5. **Sintetize uma resposta** baseada nos resultados

## ğŸ“ FORMATO DE RESPOSTA

Suas respostas devem incluir:

1. **Resumo direto** da informaÃ§Ã£o encontrada
2. **Detalhes relevantes** dos resultados
3. **Fontes** (quando disponÃ­veis nos resultados)
4. **ObservaÃ§Ãµes** sobre a qualidade/atualidade da informaÃ§Ã£o

## ğŸ’¡ EXEMPLOS DE USO

Perguntas que vocÃª responde bem:
- "Quais as Ãºltimas notÃ­cias sobre [tema]?"
- "Pesquise sobre [assunto]"
- "O que Ã© [conceito]?"
- "Como fazer [tarefa]?"
- "Encontre informaÃ§Ãµes sobre [tÃ³pico]"

## âš ï¸ LIMITAÃ‡Ã•ES

- Os resultados dependem da disponibilidade do DuckDuckGo
- InformaÃ§Ãµes podem estar desatualizadas
- Nem sempre Ã© possÃ­vel acessar o conteÃºdo completo das pÃ¡ginas
- Use os snippets/descriÃ§Ãµes retornados para sintetizar respostas

## ğŸ—£ï¸ TOM DE COMUNICAÃ‡ÃƒO

- Informativo e objetivo
- Sempre em portuguÃªs brasileiro
- Organize a informaÃ§Ã£o de forma clara
- Use formataÃ§Ã£o (negrito, listas) para facilitar a leitura
"""

    def _setup_memory(
        self,
        memory_type: str,
        max_messages: int,
        storage_path: str,
        session_id: str
    ):
        """Configura o sistema de memÃ³ria."""
        if memory_type == "none":
            return None
        elif memory_type == "short_term":
            return ShortTermMemory(max_messages=max_messages)
        elif memory_type == "long_term":
            return LongTermMemory(
                storage_path=storage_path,
                session_id=session_id
            )
        elif memory_type == "combined":
            return CombinedMemory(
                max_short_term_messages=max_messages,
                storage_path=storage_path,
                session_id=session_id
            )
        return None

    def _create_agent(self):
        """Cria o agente ReAct com LangGraph."""
        self.agent = create_react_agent(
            model=self.llm,
            tools=self.tools,
        )

    def _extract_text_from_content(self, content) -> str:
        """Extrai texto do conteÃºdo da resposta."""
        if isinstance(content, str):
            return content

        if isinstance(content, list):
            text_parts = []
            for block in content:
                if isinstance(block, dict):
                    if block.get("type") == "text":
                        text_parts.append(block.get("text", ""))
                    elif "text" in block:
                        text_parts.append(block.get("text", ""))
                elif isinstance(block, str):
                    text_parts.append(block)
            return "\n".join(text_parts)

        return str(content)

    def process_message(self, message: str) -> str:
        """
        Processa uma mensagem do usuÃ¡rio e retorna uma resposta.

        O agente irÃ¡:
        1. Analisar a pergunta
        2. Formular uma query de busca
        3. Executar a busca web
        4. Sintetizar os resultados

        Args:
            message: Pergunta ou solicitaÃ§Ã£o do usuÃ¡rio

        Returns:
            Resposta com informaÃ§Ãµes da pesquisa web
        """
        try:
            # Prepara mensagens com system prompt
            messages = [SystemMessage(content=self.system_prompt)]

            # Adiciona contexto da memÃ³ria de longo prazo
            if self.memory_type in ["long_term", "combined"]:
                long_term_context = self._get_long_term_context()
                if long_term_context:
                    messages.append(SystemMessage(content=long_term_context))

            # Adiciona histÃ³rico de curto prazo
            if self.memory_type == "combined" and self.memory:
                messages.extend(self.memory.get_short_term_messages())
            elif self.memory_type == "short_term" and self.memory:
                messages.extend(self.memory.messages)
            else:
                messages.extend(self.chat_history)

            # Adiciona a mensagem atual
            messages.append(HumanMessage(content=message))

            # Invoca o agente ReAct
            result = self.agent.invoke({"messages": messages})

            # Extrai a resposta
            response_messages = result.get("messages", [])

            if response_messages:
                last_message = response_messages[-1]
                response = self._extract_text_from_content(last_message.content)
            else:
                response = "âŒ Erro ao processar sua pesquisa."

            # Atualiza a memÃ³ria
            self._update_memory(message, response)

            return response

        except Exception as e:
            return f"âŒ Erro na pesquisa: {str(e)}"

    def _get_long_term_context(self) -> str:
        """Retorna o contexto da memÃ³ria de longo prazo."""
        if self.memory is None:
            return ""

        if self.memory_type == "long_term":
            return self.memory.get_memories_as_text(limit=5)
        elif self.memory_type == "combined":
            return self.memory.long_term.get_memories_as_text(limit=5)

        return ""

    def _update_memory(self, user_message: str, ai_response: str) -> None:
        """Atualiza a memÃ³ria com a nova interaÃ§Ã£o."""
        self.add_to_history(user_message, ai_response)

        if self.memory is None:
            return

        if self.memory_type == "short_term":
            self.memory.add_user_message(user_message)
            self.memory.add_ai_message(ai_response)
        elif self.memory_type == "combined":
            self.memory.add_user_message(user_message)
            self.memory.add_ai_message(ai_response)

    def save_to_long_term(
        self,
        content: str,
        memory_type: str = "fact",
        importance: int = 5
    ) -> None:
        """Salva uma informaÃ§Ã£o na memÃ³ria de longo prazo."""
        if self.memory is None:
            return

        if self.memory_type == "long_term":
            self.memory.add_memory(content, memory_type, importance)
        elif self.memory_type == "combined":
            self.memory.add_to_long_term(content, memory_type, importance)

    def get_memory_info(self) -> Dict[str, Any]:
        """Retorna informaÃ§Ãµes sobre a memÃ³ria atual."""
        info = {
            "type": self.memory_type,
            "enabled": self.memory is not None
        }

        if self.memory_type == "short_term" and self.memory:
            info["messages_count"] = len(self.memory.messages)
            info["max_messages"] = self.memory.max_messages
        elif self.memory_type == "long_term" and self.memory:
            info["memories_count"] = len(self.memory.memories)
        elif self.memory_type == "combined" and self.memory:
            info["short_term_messages"] = len(self.memory.short_term.messages)
            info["long_term_memories"] = len(self.memory.long_term.memories)

        return info

    def list_tools(self) -> List[str]:
        """Retorna a lista de tools disponÃ­veis."""
        return [tool.name for tool in self.tools]

    def has_rag(self) -> bool:
        """Retorna False (este agente nÃ£o usa RAG)."""
        return False

    def get_model_info(self) -> Dict[str, Any]:
        """Retorna informaÃ§Ãµes sobre o modelo."""
        return {
            "provider": self.provider,
            "model": self.model,
            "name": self.name,
            "description": self.description,
            "specialization": "web_search"
        }

    @classmethod
    def get_available_models(cls, provider: str) -> List[str]:
        """Retorna os modelos disponÃ­veis para um provider."""
        return cls.AVAILABLE_MODELS.get(provider.lower(), [])


# =============================================================================
# EXEMPLO DE USO
# =============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ” TESTE DO WEB SEARCH AGENT")
    print("=" * 60)

    # Verifica API key
    openai_key = os.getenv("OPENAI_API_KEY")

    if not openai_key:
        print("âŒ OPENAI_API_KEY nÃ£o configurada")
    else:
        print("âœ… OPENAI_API_KEY configurada")

        print("\n" + "-" * 60)
        print("Criando Web Search Agent...")

        agent = WebSearchAgent(
            provider="openai",
            model="gpt-4o-mini",
            temperature=0.5
        )

        print(f"âœ… Agente criado: {agent.name}")
        print(f"ğŸ“‹ Tools disponÃ­veis: {agent.list_tools()}")

        # Teste
        print("\n" + "-" * 60)
        print("ğŸ” Teste: Pesquisando sobre LangChain...")
        response = agent.process_message("Pesquise sobre LangChain e para que serve")
        print(response)

