"""
=============================================================================
APP.PY - Aplica√ß√£o Principal Streamlit
=============================================================================

Este √© o ponto de entrada da aplica√ß√£o.

Streamlit √© um framework que permite criar interfaces web
interativas usando apenas Python, sem precisar de HTML/CSS/JS.

Como usar:
    poetry run streamlit run app.py

Conceitos demonstrados:
1. Interface de chat interativa
2. Sele√ß√£o de diferentes agentes (OpenAI vs Gemini)
3. Configura√ß√£o din√¢mica de par√¢metros
4. Gerenciamento de estado com session_state

=============================================================================
"""

import streamlit as st
from dotenv import load_dotenv
import os

# Importa os agentes dispon√≠veis
from agents import OpenAIAgent, GeminiAgent, OllamaAgent, SimpleAgent, FinanceAgent, KnowledgeAgent, WebSearchAgent, MCPAgentDemo, MEMORY_TYPES

# Tenta importar MCPAgent real (requer depend√™ncias extras)
try:
    from agents import MCPAgent
    MCP_REAL_AVAILABLE = True
except (ImportError, TypeError):
    MCPAgent = None
    MCP_REAL_AVAILABLE = False

# Importa m√≥dulos de RAG
from knowledge_base import (
    VectorStoreManager,
    load_document,
    split_documents,
    SUPPORTED_FORMATS
)

# Carrega vari√°veis de ambiente do arquivo .env
load_dotenv()


# =============================================================================
# CONFIGURA√á√ÉO DOS AGENTES DISPON√çVEIS
# =============================================================================
# Adicione novos agentes aqui para que apare√ßam na interface
# Cada agente pode ter par√¢metros espec√≠ficos al√©m dos comuns

AVAILABLE_AGENTS = {
    "ü§ñ Simple (OpenAI)": {
        "class": SimpleAgent,
        "description": "Agente simples sem tools e RAG (OpenAI)",
        "api_key_env": "OPENAI_API_KEY",
        "api_key_url": "https://platform.openai.com/api-keys",
        "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
        "extra_params": ["presence_penalty", "frequency_penalty"],
        "provider": "openai"
    },
    "ü§ñ Simple (Gemini)": {
        "class": SimpleAgent,
        "description": "Agente simples sem tools e RAG (Gemini)",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        "extra_params": ["top_k"],
        "provider": "google"
    },
    "üõ†Ô∏è Tools (OpenAI)": {
        "class": OpenAIAgent,
        "description": "Agente usando OpenAI GPT-4 com tools",
        "api_key_env": "OPENAI_API_KEY",
        "api_key_url": "https://platform.openai.com/api-keys",
        "models": ["gpt-4", "gpt-4o"],
        # Par√¢metros espec√≠ficos do OpenAI
        "extra_params": ["presence_penalty", "frequency_penalty"]
    },
    "üõ†Ô∏è Tools (Gemini)": {
        "class": GeminiAgent,
        "description": "Agente usando Google Gemini com tools",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        # Par√¢metros espec√≠ficos do Gemini
        "extra_params": ["top_k"]
    },
    "ü¶ô Ollama (Local)": {
        "class": OllamaAgent,
        "description": "Agente usando modelos locais via Ollama (sem API key!)",
        "api_key_env": None,  # Ollama n√£o precisa de API key
        "api_key_url": "https://ollama.ai",
        "models": ["llama3.2", "llama3.1", "mistral", "codellama", "phi3", "gemma2", "gemma3", "qwen2.5"],
        # Par√¢metros espec√≠ficos do Ollama
        "extra_params": ["num_ctx", "repeat_penalty"],
        "is_local": True
    },
    # "üí∞ Finance (OpenAI)": {
    #     "class": FinanceAgent,
    #     "description": "Especialista em finan√ßas: a√ß√µes, crypto e c√¢mbio (OpenAI)",
    #     "api_key_env": "OPENAI_API_KEY",
    #     "api_key_url": "https://platform.openai.com/api-keys",
    #     "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
    #     "extra_params": ["presence_penalty", "frequency_penalty"],
    #     "provider": "openai",
    #     "is_specialist": True
    # },
    "üí∞ Finance (Gemini)": {
        "class": FinanceAgent,
        "description": "Especialista em finan√ßas: a√ß√µes, crypto e c√¢mbio (Gemini)",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        "extra_params": ["top_k"],
        "provider": "google",
        "is_specialist": True
    },
    # "üìö Knowledge (OpenAI)": {
    #     "class": KnowledgeAgent,
    #     "description": "Especialista em conhecimento: Wikipedia e informa√ß√µes enciclop√©dicas (OpenAI)",
    #     "api_key_env": "OPENAI_API_KEY",
    #     "api_key_url": "https://platform.openai.com/api-keys",
    #     "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
    #     "extra_params": ["presence_penalty", "frequency_penalty"],
    #     "provider": "openai",
    #     "is_specialist": True
    # },
    "üìö Knowledge (Gemini)": {
        "class": KnowledgeAgent,
        "description": "Especialista em conhecimento: Wikipedia e informa√ß√µes enciclop√©dicas (Gemini)",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        "extra_params": ["top_k"],
        "provider": "google",
        "is_specialist": True
    },
    # "üîç Web Search (OpenAI)": {
    #     "class": WebSearchAgent,
    #     "description": "Especialista em pesquisa web: busca informa√ß√µes atualizadas na internet (OpenAI)",
    #     "api_key_env": "OPENAI_API_KEY",
    #     "api_key_url": "https://platform.openai.com/api-keys",
    #     "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
    #     "extra_params": ["presence_penalty", "frequency_penalty"],
    #     "provider": "openai",
    #     "is_specialist": True
    # },
    "üîç Web Search (Gemini)": {
        "class": WebSearchAgent,
        "description": "Especialista em pesquisa web: busca informa√ß√µes atualizadas na internet (Gemini)",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        "extra_params": ["top_k"],
        "provider": "google",
        "is_specialist": True
    },
    # "üîå MCP Demo (OpenAI)": {
    #     "class": MCPAgentDemo,
    #     "description": "Demonstra√ß√£o do Model Context Protocol (MCP) - conecta a servidores externos (OpenAI)",
    #     "api_key_env": "OPENAI_API_KEY",
    #     "api_key_url": "https://platform.openai.com/api-keys",
    #     "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
    #     "extra_params": ["presence_penalty", "frequency_penalty"],
    #     "provider": "openai",
    #     "is_specialist": True,
    #     "mcp_server": "fetch"
    # },
    "üîå MCP Demo (Gemini)": {
        "class": MCPAgentDemo,
        "description": "Demonstra√ß√£o do Model Context Protocol (MCP) - conecta a servidores externos (Gemini)",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        "extra_params": ["top_k"],
        "provider": "google",
        "is_specialist": True,
        "mcp_server": "fetch"
    }
}

# Adiciona MCPAgent real se dispon√≠vel
if MCP_REAL_AVAILABLE and MCPAgent is not None:
    # AVAILABLE_AGENTS["üîå MCP Fetch (OpenAI)"] = {
    #     "class": MCPAgent,
    #     "description": "üåê MCP REAL: Busca e extrai conte√∫do de URLs (OpenAI)",
    #     "api_key_env": "OPENAI_API_KEY",
    #     "api_key_url": "https://platform.openai.com/api-keys",
    #     "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
    #     "extra_params": ["presence_penalty", "frequency_penalty"],
    #     "provider": "openai",
    #     "is_specialist": True,
    #     "mcp_server": "fetch"
    # }
    AVAILABLE_AGENTS["üîå MCP Fetch (Gemini)"] = {
        "class": MCPAgent,
        "description": "üåê MCP REAL: Busca e extrai conte√∫do de URLs (Gemini)",
        "api_key_env": "GOOGLE_API_KEY",
        "api_key_url": "https://makersuite.google.com/app/apikey",
        "models": ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-3.0-flash"],
        "extra_params": ["top_k"],
        "provider": "google",
        "is_specialist": True,
        "mcp_server": "fetch"
    }
    AVAILABLE_AGENTS["üîå MCP Time (OpenAI)"] = {
        "class": MCPAgent,
        "description": "üïê MCP REAL: Informa√ß√µes de data, hora e fuso hor√°rio (OpenAI)",
        "api_key_env": "OPENAI_API_KEY",
        "api_key_url": "https://platform.openai.com/api-keys",
        "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
        "extra_params": ["presence_penalty", "frequency_penalty"],
        "provider": "openai",
        "is_specialist": True,
        "mcp_server": "time"
    }
    AVAILABLE_AGENTS["üîå MCP Filesystem (OpenAI)"] = {
        "class": MCPAgent,
        "description": "üìÅ MCP REAL: L√™ e escreve arquivos locais (OpenAI)",
        "api_key_env": "OPENAI_API_KEY",
        "api_key_url": "https://platform.openai.com/api-keys",
        "models": ["gpt-4o-mini", "gpt-4o", "gpt-4"],
        "extra_params": ["presence_penalty", "frequency_penalty"],
        "provider": "openai",
        "is_specialist": True,
        "mcp_server": "filesystem"
    }


# =============================================================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# =============================================================================
st.set_page_config(
    page_title="AI Agent Chat - Trilha Master GenAI",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado para melhorar a apar√™ncia
st.markdown("""
<style>
    /* Estilo do cabe√ßalho */
    .main-header {
        text-align: center;
        padding: 1rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    /* Cards de informa√ß√£o */
    .info-card {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #f0f2f6;
        margin-bottom: 1rem;
    }
    
    /* Destaque para tools */
    .tool-badge {
        display: inline-block;
        padding: 0.25rem 0.5rem;
        margin: 0.25rem;
        border-radius: 1rem;
        background-color: #e1e5eb;
        font-size: 0.8rem;
    }
</style>
""", unsafe_allow_html=True)


# =============================================================================
# FUN√á√ïES AUXILIARES
# =============================================================================

def create_agent(
    agent_name: str,
    model: str,
    temperature: float,
    system_prompt: str,
    guardrails: str = "",
    max_tokens: int = None,
    top_p: float = 1.0,
    presence_penalty: float = 0.0,
    frequency_penalty: float = 0.0,
    top_k: int = None,
    vector_store_manager=None,
    # Par√¢metros de mem√≥ria
    memory_type: str = "short_term",
    memory_max_messages: int = 20,
    memory_storage_path: str = "./memory_data",
    memory_session_id: str = "default"
):
    """
    Cria uma inst√¢ncia do agente selecionado com todos os par√¢metros.

    Esta fun√ß√£o √© chamada quando o usu√°rio:
    - Seleciona um novo agente
    - Muda o modelo
    - Clica em "Aplicar Configura√ß√µes"

    Args:
        agent_name: Nome do agente selecionado
        model: Modelo a usar
        temperature: Temperatura para gera√ß√£o (criatividade)
        system_prompt: Prompt de sistema customizado
        guardrails: Regras de seguran√ßa adicionadas ao final do system prompt
        max_tokens: Limite de tokens na resposta (None = ilimitado)
        top_p: Nucleus sampling (0.0 a 1.0)
        presence_penalty: Penalidade por repetir t√≥picos (OpenAI)
        frequency_penalty: Penalidade por repetir palavras (OpenAI)
        top_k: Top-K sampling (Gemini)
        vector_store_manager: Gerenciador de vector store para RAG
        memory_type: Tipo de mem√≥ria (none, short_term, long_term, combined)
        memory_max_messages: M√°ximo de mensagens no curto prazo
        memory_storage_path: Caminho para salvar mem√≥ria de longo prazo
        memory_session_id: ID da sess√£o de mem√≥ria

    Returns:
        Inst√¢ncia do agente ou None se houver erro
    """
    agent_config = AVAILABLE_AGENTS[agent_name]
    agent_class = agent_config["class"]

    try:
        # Combina system_prompt com guardrails
        full_system_prompt = system_prompt.strip()
        if guardrails.strip():
            full_system_prompt += f"\n\n{guardrails.strip()}"

        # Par√¢metros comuns a todos os agentes
        common_params = {
            "name": agent_name,
            "description": agent_config["description"],
            "model": model,
            "temperature": temperature,
            "system_prompt": full_system_prompt if full_system_prompt else None,
            "max_tokens": max_tokens,
            "top_p": top_p,
            # Par√¢metros de mem√≥ria
            "memory_type": memory_type,
            "memory_max_messages": memory_max_messages,
            "memory_storage_path": memory_storage_path,
            "memory_session_id": memory_session_id,
        }

        # Verifica se √© um agente com provider (SimpleAgent ou FinanceAgent)
        has_provider = "provider" in agent_config
        is_specialist = agent_config.get("is_specialist", False)

        if has_provider:
            # Agentes com provider (SimpleAgent, FinanceAgent)
            common_params["provider"] = agent_config["provider"]

        if not has_provider and not is_specialist:
            # Agentes gen√©ricos com tools (OpenAI, Gemini) usam vector_store_manager
            common_params["vector_store_manager"] = vector_store_manager

        # Adiciona par√¢metros espec√≠ficos do OpenAI
        if "OpenAI" in agent_name or "Finance (OpenAI)" in agent_name:
            common_params["presence_penalty"] = presence_penalty
            common_params["frequency_penalty"] = frequency_penalty

        # Adiciona par√¢metros espec√≠ficos do Gemini
        if "Gemini" in agent_name or "Finance (Gemini)" in agent_name:
            common_params["top_k"] = top_k

        # Adiciona par√¢metros espec√≠ficos do Ollama
        if "Ollama" in agent_name:
            # Ollama n√£o usa max_tokens, usa num_predict
            common_params["num_predict"] = max_tokens
            del common_params["max_tokens"]
            # Adiciona vector_store_manager para RAG
            common_params["vector_store_manager"] = vector_store_manager

        # Adiciona par√¢metros espec√≠ficos do MCP
        if "mcp_server" in agent_config:
            common_params["mcp_server_name"] = agent_config["mcp_server"]

        agent = agent_class(**common_params)
        return agent

    except ValueError as e:
        # Erro geralmente significa API key n√£o configurada
        st.error(f"‚ö†Ô∏è {str(e)}")
        return None


def initialize_session_state():
    """
    Inicializa o estado da sess√£o do Streamlit.

    session_state √© como uma "mem√≥ria" que persiste entre
    as intera√ß√µes do usu√°rio. Sem ela, cada clique
    recarregaria toda a p√°gina e perderia os dados.
    """
    # Dicion√°rio de chats: {chat_id: {"name": str, "messages": list, "agent": obj}}
    if "chats" not in st.session_state:
        st.session_state.chats = {
            "chat_1": {
                "name": "Chat 1",
                "messages": [],
                "agent": None,
                "agent_name": None,
                "model": None,
                "config": None  # Armazena toda a configura√ß√£o do chat
            }
        }

    # ID do chat ativo
    if "active_chat_id" not in st.session_state:
        st.session_state.active_chat_id = "chat_1"

    # Contador para gerar IDs √∫nicos
    if "chat_counter" not in st.session_state:
        st.session_state.chat_counter = 1

    # Manter compatibilidade com c√≥digo existente
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "agent" not in st.session_state:
        st.session_state.agent = None

    if "current_agent_name" not in st.session_state:
        st.session_state.current_agent_name = None

    # RAG - Base de Conhecimento
    if "vector_store_manager" not in st.session_state:
        st.session_state.vector_store_manager = None

    if "rag_documents" not in st.session_state:
        st.session_state.rag_documents = []  # Lista de documentos carregados

    if "rag_storage_path" not in st.session_state:
        st.session_state.rag_storage_path = None  # Caminho onde a base est√° salva (None = mem√≥ria)

    # Configura√ß√£o atual do chat (para persistir entre reloads)
    if "current_model" not in st.session_state:
        st.session_state.current_model = None

    if "current_config" not in st.session_state:
        st.session_state.current_config = None


def get_active_chat():
    """Retorna o chat ativo atual."""
    return st.session_state.chats.get(st.session_state.active_chat_id, None)


def create_new_chat():
    """Cria um novo chat e o torna ativo, preservando o agente selecionado."""
    # Guarda o agente e modelo do chat atual antes de criar o novo
    current_chat = st.session_state.chats.get(st.session_state.active_chat_id, {})
    current_agent_name = current_chat.get("agent_name") or st.session_state.current_agent_name
    current_model = current_chat.get("model") or st.session_state.current_model
    current_config = current_chat.get("config") or st.session_state.current_config

    st.session_state.chat_counter += 1
    new_id = f"chat_{st.session_state.chat_counter}"
    st.session_state.chats[new_id] = {
        "name": f"Chat {st.session_state.chat_counter}",
        "messages": [],
        "agent": None,  # Ser√° recriado quando o usu√°rio enviar mensagem
        "agent_name": current_agent_name,  # Preserva o agente selecionado
        "model": current_model,  # Preserva o modelo selecionado
        "config": current_config  # Preserva as configura√ß√µes
    }
    st.session_state.active_chat_id = new_id
    # Sincroniza com vari√°veis de compatibilidade
    st.session_state.messages = []
    st.session_state.agent = None  # Ser√° recriado
    # Mant√©m o agente e modelo selecionados (n√£o reseta para None)
    # st.session_state.current_agent_name permanece o mesmo
    # st.session_state.current_model permanece o mesmo
    return new_id


def switch_chat(chat_id: str):
    """Alterna para um chat espec√≠fico, carregando suas configura√ß√µes."""
    if chat_id in st.session_state.chats:
        st.session_state.active_chat_id = chat_id
        chat = st.session_state.chats[chat_id]
        # Sincroniza com vari√°veis de compatibilidade
        st.session_state.messages = chat["messages"]
        st.session_state.agent = chat["agent"]
        st.session_state.current_agent_name = chat["agent_name"]
        # Carrega o modelo do chat se existir
        if "model" in chat:
            st.session_state.current_model = chat.get("model")
        if "config" in chat:
            st.session_state.current_config = chat.get("config")


def delete_chat(chat_id: str):
    """Remove um chat (n√£o pode remover o √∫ltimo)."""
    if len(st.session_state.chats) > 1 and chat_id in st.session_state.chats:
        del st.session_state.chats[chat_id]
        # Se deletou o chat ativo, muda para outro
        if st.session_state.active_chat_id == chat_id:
            st.session_state.active_chat_id = list(st.session_state.chats.keys())[0]
            switch_chat(st.session_state.active_chat_id)


def rename_chat(chat_id: str, new_name: str):
    """Renomeia um chat."""
    if chat_id in st.session_state.chats:
        st.session_state.chats[chat_id]["name"] = new_name


def clear_chat(chat_id: str):
    """Limpa as mensagens de um chat (reinicia a conversa), mantendo o agente."""
    if chat_id in st.session_state.chats:
        st.session_state.chats[chat_id]["messages"] = []
        # Se for o chat ativo, sincroniza
        if chat_id == st.session_state.active_chat_id:
            st.session_state.messages = []
            # Limpa apenas o hist√≥rico do agente, mas mant√©m o agente
            if st.session_state.agent:
                st.session_state.agent.clear_history()
        # Mant√©m as configura√ß√µes do agente (agent, agent_name, model, config)


def sync_active_chat(config: dict = None):
    """Sincroniza o estado do chat ativo com as vari√°veis globais."""
    chat_id = st.session_state.active_chat_id
    if chat_id in st.session_state.chats:
        st.session_state.chats[chat_id]["messages"] = st.session_state.messages
        st.session_state.chats[chat_id]["agent"] = st.session_state.agent
        st.session_state.chats[chat_id]["agent_name"] = st.session_state.current_agent_name
        # Salva as configura√ß√µes se fornecidas
        if config:
            st.session_state.chats[chat_id]["model"] = config.get("model")
            st.session_state.chats[chat_id]["config"] = config


def display_sidebar():
    """
    Renderiza a barra lateral com configura√ß√µes.

    A sidebar cont√©m:
    - Sele√ß√£o de agente
    - Input de API key
    - Sele√ß√£o de modelo
    - Slider de temperatura
    - √Årea de system prompt
    - Bot√µes de a√ß√£o

    Returns:
        Tupla com as configura√ß√µes selecionadas
    """
    with st.sidebar:
        # -----------------------------------------------------------------
        # GERENCIAMENTO DE CHATS
        # -----------------------------------------------------------------
        st.subheader("üí¨ Chats")

        # Bot√£o para criar novo chat
        if st.button("‚ûï Novo Chat", use_container_width=True):
            create_new_chat()
            st.rerun()

        with st.expander("Hist√≥rico das Conversas", expanded=False):
            # Lista de chats existentes
            for chat_id, chat_data in st.session_state.chats.items():
                is_active = chat_id == st.session_state.active_chat_id

                col1, col2 = st.columns([4, 1])

                with col1:
                    # Monta o label do chat com informa√ß√µes do agente
                    chat_label = chat_data['name']
                    if chat_data.get('agent_name'):
                        chat_label += f" ({chat_data['agent_name']})"

                    # Bot√£o para selecionar o chat
                    if st.button(
                        f"{'' if is_active else ''}{chat_label}",
                        key=f"select_{chat_id}",
                        type="primary" if is_active else "secondary",
                        use_container_width=True
                    ):
                        if not is_active:
                            sync_active_chat()  # Salva o chat atual antes de trocar
                            switch_chat(chat_id)
                            st.rerun()

                with col2:
                    # Bot√£o sempre vis√≠vel
                    if len(st.session_state.chats) > 1:
                        # Se h√° mais de 1 chat, exclui o chat
                        if st.button("üóëÔ∏è", key=f"delete_{chat_id}", help="Excluir chat"):
                            delete_chat(chat_id)
                            st.rerun()
                    else:
                        # Se √© o √∫nico chat, limpa a conversa
                        if st.button("üóëÔ∏è", key=f"clear_{chat_id}", help="Limpar conversa"):
                            clear_chat(chat_id)
                            st.rerun()

        st.divider()

        # -----------------------------------------------------------------
        # CABE√áALHO
        # -----------------------------------------------------------------
        st.header("‚öôÔ∏è Configura√ß√µes")

        # -----------------------------------------------------------------
        # SELE√á√ÉO DE AGENTE
        # -----------------------------------------------------------------
        st.subheader("1. Escolha o Agente")

        # Obt√©m a configura√ß√£o salva do chat ativo (se existir)
        active_chat = st.session_state.chats.get(st.session_state.active_chat_id, {})
        saved_agent_name = active_chat.get("agent_name")
        saved_model = active_chat.get("model")

        # Determina o √≠ndice do agente selecionado
        agent_options = list(AVAILABLE_AGENTS.keys())
        default_agent_index = 0
        if saved_agent_name and saved_agent_name in agent_options:
            default_agent_index = agent_options.index(saved_agent_name)

        # Usa key √∫nica para o chat ativo - isso garante que ao trocar de chat,
        # o selectbox seja recriado com o valor correto
        agent_select_key = f"agent_select_{st.session_state.active_chat_id}"

        selected_agent = st.selectbox(
            "Agente de IA",
            options=agent_options,
            index=default_agent_index,
            key=agent_select_key,
            help="Escolha qual agente de IA usar"
        )

        agent_config = AVAILABLE_AGENTS[selected_agent]

        # Determina o √≠ndice do modelo selecionado
        model_options = agent_config["models"]
        default_model_index = 0
        if saved_model and saved_model in model_options and saved_agent_name == selected_agent:
            default_model_index = model_options.index(saved_model)

        # Usa key √∫nica vinculada ao chat e ao agente - ao mudar de agente,
        # o selectbox de modelo √© recriado com as op√ß√µes corretas
        model_select_key = f"model_select_{st.session_state.active_chat_id}_{selected_agent}"

        model = st.selectbox(
            "Modelo",
            options=model_options,
            index=default_model_index,
            key=model_select_key,
            help="Modelos mais capazes geralmente s√£o mais lentos e caros"
        )

        # Mostra descri√ß√£o do agente
        st.caption(agent_config["description"])

        # -----------------------------------------------------------------
        # CONFIGURA√á√ïES DO MODELO
        # -----------------------------------------------------------------
        st.subheader("2. Configura√ß√µes do Modelo")

        # Par√¢metros avan√ßados dentro de um expander
        # Valores padr√£o (caso o expander n√£o seja aberto)
        temperature = 0.7
        max_tokens = None
        top_p = 1.0
        presence_penalty = 0.0
        frequency_penalty = 0.0
        top_k = None

        with st.expander("Par√¢metros Avan√ßados", expanded=False):
            st.caption("Ajuste fino do comportamento do modelo")

            # Temperatura - controla criatividade (sempre vis√≠vel)
            temperature = st.slider(
                "Temperatura",
                min_value=0.0,
                max_value=2.0,
                value=0.7,
                step=0.1,
                help="""
                          Controla a criatividade/aleatoriedade:
                          - 0.0 = Respostas mais determin√≠sticas e focadas
                          - 0.7 = Balanceado (recomendado)
                          - 2.0 = Muito criativo (pode ser confuso)
                          """
            )

            # Max Tokens - limite de resposta
            max_tokens = st.slider(
                "Max Tokens",
                min_value=50,
                max_value=4096,
                value=1024,
                step=50,
                help="""
                       N√∫mero m√°ximo de tokens na resposta.
                       1 token ‚âà 4 caracteres em ingl√™s, 2-3 em portugu√™s.
                       - 256 = Respostas curtas
                       - 1024 = Respostas m√©dias
                       - 4096 = Respostas longas
                       """
            )

            # Top P - Nucleus Sampling
            top_p = st.slider(
                "Top P (Nucleus Sampling)",
                min_value=0.0,
                max_value=1.0,
                value=1.0,
                step=0.05,
                help="""
                       Alternativa √† temperatura para controlar aleatoriedade.
                       Considera apenas tokens cuja probabilidade acumulada ‚â§ top_p.
                       - 1.0 = Considera todos os tokens
                       - 0.9 = Considera os 90% mais prov√°veis
                       - 0.5 = Mais focado, menos diversidade

                       üí° Dica: Use temperatura OU top_p, n√£o ambos!
                       """
            )

            # Par√¢metros espec√≠ficos do OpenAI
            if selected_agent == "OpenAI":
                st.markdown("---")
                st.markdown("##### Par√¢metros OpenAI")

                presence_penalty = st.slider(
                    "Presence Penalty",
                    min_value=-2.0,
                    max_value=2.0,
                    value=0.0,
                    step=0.1,
                    help="""
                           Penaliza tokens que j√° apareceram no texto.
                           - Valores positivos = Incentiva novos t√≥picos
                           - Valores negativos = Permite repeti√ß√£o de t√≥picos
                           - 0.0 = Sem efeito
                           """
                )

                frequency_penalty = st.slider(
                    "Frequency Penalty",
                    min_value=-2.0,
                    max_value=2.0,
                    value=0.0,
                    step=0.1,
                    help="""
                           Penaliza tokens baseado na frequ√™ncia de uso.
                           - Valores positivos = Evita repetir palavras
                           - Valores negativos = Permite mais repeti√ß√£o
                           - 0.0 = Sem efeito
                           """
                )

            # Par√¢metros espec√≠ficos do Gemini
            if selected_agent == "Gemini":
                st.markdown("---")
                st.markdown("##### Par√¢metros Gemini")

                top_k = st.slider(
                    "Top K",
                    min_value=1,
                    max_value=100,
                    value=40,
                    step=1,
                    help="""
                           Considera apenas os K tokens mais prov√°veis.
                           - Valores baixos (1-10) = Mais determin√≠stico
                           - Valores m√©dios (20-40) = Balanceado
                           - Valores altos (50-100) = Mais diversidade

                           üí° Use junto com top_p para controle fino.
                           """
                )

            # Par√¢metros espec√≠ficos do Ollama
            if "Ollama" in selected_agent:
                st.markdown("---")
                st.markdown("##### Par√¢metros Ollama")
                st.info("ü¶ô Ollama roda localmente - n√£o precisa de API key!")

                top_k = st.slider(
                    "Top K",
                    min_value=1,
                    max_value=100,
                    value=40,
                    step=1,
                    help="""
                           Considera apenas os K tokens mais prov√°veis.
                           - Valores baixos (1-10) = Mais determin√≠stico
                           - Valores m√©dios (20-40) = Balanceado
                           - Valores altos (50-100) = Mais diversidade
                           """
                )

        # -----------------------------------------------------------------
        # API KEY (n√£o mostrar para Ollama)
        # -----------------------------------------------------------------
        st.subheader("3. Configura√ß√µes de Acesso")

        # Ollama n√£o precisa de API Key
        is_local_agent = agent_config.get("is_local", False)

        if is_local_agent:
            st.success("‚úÖ Este agente roda localmente via Ollama - n√£o precisa de API key!")
            st.markdown("""
            **Certifique-se de que:**
            1. Ollama est√° instalado ([baixe aqui](https://ollama.ai))
            2. O servidor est√° rodando (execute `ollama serve` no terminal)
            3. O modelo est√° baixado (execute `ollama pull llama3.2`)
            """)
        else:
            with st.expander("Informar API Key", expanded=False):
                st.caption("Configurar API Key para o agente funcionar")

                api_key_env = agent_config["api_key_env"]
                current_key = os.getenv(api_key_env, "")

                api_key = st.text_input(
                    f"{api_key_env}",
                    value=current_key,
                    type="password",
                    help=f"Obtenha em: {agent_config['api_key_url']}"
                )

                # Atualiza a vari√°vel de ambiente se mudou
                if api_key and api_key != current_key:
                    os.environ[api_key_env] = api_key
                    # For√ßa recriar o agente
                    if "agent" in st.session_state:
                        st.session_state.agent = None

                # Link para obter API key
                st.markdown(f"[üîë Obter API Key]({agent_config['api_key_url']})")

        st.divider()

        # -----------------------------------------------------------------
        # PERSONALIDADE DO AGENTE
        # -----------------------------------------------------------------
        st.subheader("4. Personalidade do Agente")

        # Mensagem de Boas-vindas
        with st.expander("üëã Boas-vindas", expanded=False):
            welcome_message = st.text_area(
                "Mensagem inicial exibida no chat",
                value="""Ol√°! üëã Sou seu assistente de IA.

                Posso ajud√°-lo com:
                ‚Ä¢ C√°lculos matem√°ticos
                ‚Ä¢ Informa√ß√µes de data e hora
                ‚Ä¢ Pesquisas na web
                
                Como posso ajudar voc√™ hoje?""",
            height=120,
            help="""
            Mensagem exibida quando o chat √© iniciado.
            Use para apresentar o agente e suas capacidades.
            """
        )

        # System Prompt
        with st.expander("üß† System Prompt", expanded=False):
            system_prompt = st.text_area(
                "Define o comportamento do agente",
                value="""Voc√™ √© um assistente √∫til e amig√°vel.
                Responda de forma clara e educada.
                Use as ferramentas dispon√≠veis quando necess√°rio.""",
                height=120,
                help="""
                Define o comportamento e personalidade do agente.
                O usu√°rio N√ÉO v√™ este prompt, mas ele influencia
                como o agente responde.
                """
            )

        # Guardrails
        with st.expander("üõ°Ô∏è Guardrails", expanded=False):
            guardrails = st.text_area(
                "Regras de Seguran√ßa e Limites",
                value="""REGRAS QUE VOC√ä DEVE SEGUIR:
                1. Nunca forne√ßa informa√ß√µes falsas
                2. Se n√£o souber algo, admita
                3. N√£o discuta temas ilegais ou anti√©ticos
                4. Mantenha respostas respeitosas e profissionais
                5. Proteja a privacidade dos usu√°rios""",
                height=120,
                help="""
                Regras de seguran√ßa e limites que o agente deve respeitar.
                Guardrails ajudam a evitar respostas inadequadas.
                S√£o adicionados ao final do system prompt.
                """
            )

        # -----------------------------------------------------------------
        # BOT√ïES DE A√á√ÉO
        # -----------------------------------------------------------------
        col1, col2 = st.columns(2)

        with col1:
            if st.button("Aplicar", type="primary", use_container_width=True):
                st.session_state.agent = None
                st.session_state.messages = []
                st.rerun()

        with col2:
            if st.button("Limpar", use_container_width=True):
                st.session_state.messages = []
                if st.session_state.agent:
                    st.session_state.agent.clear_history()
                st.rerun()

        st.divider()

        # -----------------------------------------------------------------
        # CONFIGURA√á√ÉO DE MEM√ìRIA
        # -----------------------------------------------------------------
        st.subheader("5. Mem√≥ria do Agente")

        with st.expander("üß† Configurar Mem√≥ria", expanded=False):
            st.caption("""
            Configure como o agente lembra das conversas.
            """)

            # Sele√ß√£o do tipo de mem√≥ria
            memory_type = st.selectbox(
                "Tipo de Mem√≥ria",
                options=list(MEMORY_TYPES.keys()),
                format_func=lambda x: f"{MEMORY_TYPES[x]['icon']} {MEMORY_TYPES[x]['name']}",
                help="Escolha como o agente vai lembrar das conversas"
            )

            # Mostra descri√ß√£o do tipo selecionado
            st.caption(MEMORY_TYPES[memory_type]["description"])

            # Configura√ß√µes espec√≠ficas por tipo
            memory_max_messages = 20
            memory_storage_path = "./memory_data"
            memory_session_id = "default"

            if memory_type in ["short_term", "combined"]:
                memory_max_messages = st.slider(
                    "M√°ximo de Mensagens (Curto Prazo)",
                    min_value=5,
                    max_value=50,
                    value=20,
                    step=5,
                    help="Quantas mensagens manter no hist√≥rico de curto prazo"
                )

            if memory_type in ["long_term", "combined"]:
                memory_storage_path = st.text_input(
                    "Caminho para Salvar Mem√≥ria",
                    value="./memory_data",
                    help="Diret√≥rio onde as mem√≥rias de longo prazo ser√£o salvas"
                )

                memory_session_id = st.text_input(
                    "ID da Sess√£o",
                    value="default",
                    help="Identificador √∫nico para esta sess√£o de mem√≥ria"
                )

            # Placeholder para status da mem√≥ria (ser√° atualizado depois)
            memory_status_placeholder = st.empty()

        st.divider()

        # -----------------------------------------------------------------
        # BASE DE CONHECIMENTO (RAG)
        # -----------------------------------------------------------------
        st.subheader("6. Base de Conhecimento")

        with st.expander("üìö RAG - Upload de Documentos", expanded=False):
            st.caption("""
            Carregue documentos para o agente consultar.
            O agente poder√° buscar informa√ß√µes relevantes
            para responder suas perguntas.
            """)

            # Mostra formatos suportados
            formats_list = ", ".join(SUPPORTED_FORMATS.keys())
            st.info(f"üìÅ Formatos suportados: {formats_list}")

            # Upload de arquivos - agora aceita mais formatos
            uploaded_files = st.file_uploader(
                "Selecione arquivos",
                type=["txt", "md", "pdf", "csv", "docx", "json"],
                accept_multiple_files=True,
                help="Arraste arquivos ou clique para selecionar"
            )

            # Configura√ß√µes de chunking
            col1, col2 = st.columns(2)
            with col1:
                chunk_size = st.number_input(
                    "Tamanho do Chunk",
                    min_value=100,
                    max_value=4000,
                    value=1000,
                    step=100,
                    help="Tamanho de cada peda√ßo de texto"
                )
            with col2:
                chunk_overlap = st.number_input(
                    "Overlap",
                    min_value=0,
                    max_value=500,
                    value=200,
                    step=50,
                    help="Sobreposi√ß√£o entre chunks"
                )

            # Op√ß√£o de persist√™ncia
            st.markdown("---")
            st.markdown("##### üíæ Armazenamento")

            storage_option = st.radio(
                "Onde armazenar a base de conhecimento?",
                options=["memory", "disk"],
                format_func=lambda x: "üß† Mem√≥ria (tempor√°rio)" if x == "memory" else "üíæ Disco (persistente)",
                help="""
                **Mem√≥ria**: Mais r√°pido, mas perde os dados ao fechar o app.
                **Disco**: Mais lento para criar, mas mant√©m os dados entre sess√µes.
                """,
                horizontal=True
            )

            # Caminho para salvar (s√≥ aparece se escolher disco)
            save_path = None
            if storage_option == "disk":
                save_path = st.text_input(
                    "Caminho para salvar",
                    value="./knowledge_base_data",
                    help="Diret√≥rio onde os dados ser√£o salvos"
                )

            # Bot√£o para processar documentos
            if st.button("üì• Processar Documentos", use_container_width=True):
                if uploaded_files:
                    with st.spinner("Processando documentos..."):
                        try:
                            all_documents = []

                            for uploaded_file in uploaded_files:
                                st.text(f"üìÑ Processando: {uploaded_file.name}")

                                # Usa a fun√ß√£o universal load_document
                                docs = load_document(
                                    file_content=uploaded_file.read(),
                                    filename=uploaded_file.name
                                )
                                all_documents.extend(docs)

                            # Divide em chunks
                            chunks = split_documents(
                                all_documents,
                                chunk_size=chunk_size,
                                chunk_overlap=chunk_overlap
                            )

                            # Cria vector store
                            vector_manager = VectorStoreManager()
                            vector_manager.create_from_documents(chunks)

                            # Salva em disco se solicitado
                            if storage_option == "disk" and save_path:
                                vector_manager.save(save_path)
                                st.info(f"üíæ Base salva em: {save_path}")

                            # Salva no session_state
                            st.session_state.vector_store_manager = vector_manager
                            st.session_state.rag_documents = [f.name for f in uploaded_files]
                            st.session_state.rag_storage_path = save_path if storage_option == "disk" else None

                            # For√ßa recriar o agente com RAG
                            st.session_state.agent = None

                            st.success(
                                f"‚úÖ {len(chunks)} chunks criados de "
                                f"{len(uploaded_files)} arquivo(s)!"
                            )
                            st.rerun()

                        except ImportError as e:
                            st.error(f"‚ùå Biblioteca necess√°ria n√£o instalada: {str(e)}")
                        except Exception as e:
                            st.error(f"‚ùå Erro ao processar: {str(e)}")
                else:
                    st.warning("Selecione pelo menos um arquivo.")

            # Se√ß√£o para carregar base existente do disco
            st.markdown("---")
            st.markdown("##### üìÇ Carregar Base Existente")

            load_path = st.text_input(
                "Caminho da base salva",
                value="./knowledge_base_data",
                key="load_kb_path",
                help="Diret√≥rio onde a base foi salva anteriormente"
            )

            if st.button("üìÇ Carregar do Disco", use_container_width=True):
                if load_path:
                    try:
                        with st.spinner("Carregando base de conhecimento..."):
                            vector_manager = VectorStoreManager()
                            vector_manager.load(load_path)

                            st.session_state.vector_store_manager = vector_manager
                            st.session_state.rag_documents = [f"Base carregada de: {load_path}"]
                            st.session_state.rag_storage_path = load_path
                            st.session_state.agent = None

                            st.success("‚úÖ Base de conhecimento carregada!")
                            st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå Erro ao carregar: {str(e)}")
                else:
                    st.warning("Informe o caminho da base.")

            # Mostra documentos carregados
            if st.session_state.rag_documents:
                st.markdown("---")
                st.markdown("**üìã Status da Base:**")
                for doc_name in st.session_state.rag_documents:
                    st.markdown(f"‚Ä¢ {doc_name}")

                # Mostra onde est√° armazenado
                if hasattr(st.session_state, 'rag_storage_path') and st.session_state.rag_storage_path:
                    st.caption(f"üíæ Salvo em: {st.session_state.rag_storage_path}")
                else:
                    st.caption("üß† Armazenado em mem√≥ria (tempor√°rio)")

                if st.button("üóëÔ∏è Limpar Base de Conhecimento", use_container_width=True):
                    st.session_state.vector_store_manager = None
                    st.session_state.rag_documents = []
                    st.session_state.rag_storage_path = None
                    st.session_state.agent = None
                    st.success("Base de conhecimento limpa!")
                    st.rerun()

        st.divider()

        # -----------------------------------------------------------------
        # SOBRE
        # -----------------------------------------------------------------
        st.subheader("Sobre o Projeto")
        with st.expander("Trilha Master GenAI", expanded=False):
            st.markdown("""
            Este projeto demonstra:
            - Cria√ß√£o de Agentes de IA
            - Uso do Framework LangChain
            - Uso de Tools (Ferramentas)
            - Uso de RAG (Base de Conhecimento)
            - Interface com Streamlit
            """)

        # Retorna todos os par√¢metros configurados
        return {
            "agent_name": selected_agent,
            "model": model,
            "temperature": temperature,
            "welcome_message": welcome_message,
            "system_prompt": system_prompt,
            "guardrails": guardrails,
            "max_tokens": max_tokens,
            "top_p": top_p,
            "presence_penalty": presence_penalty,
            "frequency_penalty": frequency_penalty,
            "top_k": top_k,
            # Par√¢metros de mem√≥ria
            "memory_type": memory_type,
            "memory_max_messages": memory_max_messages,
            "memory_storage_path": memory_storage_path,
            "memory_session_id": memory_session_id,
            # Placeholder para atualiza√ß√£o din√¢mica
            "memory_status_placeholder": memory_status_placeholder
        }


def display_agent_info(agent):
    """
    Mostra informa√ß√µes sobre o agente atual.

    √ötil para debug e para o usu√°rio saber
    quais ferramentas est√£o dispon√≠veis.
    """
    if agent is None:
        return

    with st.expander("Informa√ß√µes do Agente", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.write(f"**Nome:** {agent.name}")
            st.write(f"**Descri√ß√£o:** {agent.description}")

        with col2:
            st.write("**Tools Dispon√≠veis:**")
            for tool_name in agent.list_tools():
                st.write(f"  ‚Ä¢ {tool_name}")


# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """
    Fun√ß√£o principal da aplica√ß√£o.

    Fluxo:
    1. Inicializa o estado da sess√£o
    2. Renderiza a sidebar com configura√ß√µes
    3. Cria/atualiza o agente se necess√°rio
    4. Exibe o hist√≥rico de mensagens
    5. Processa novas mensagens do usu√°rio
    """

    # -----------------------------------------------------------------
    # INICIALIZA√á√ÉO
    # -----------------------------------------------------------------
    initialize_session_state()

    # Carrega o chat ativo
    switch_chat(st.session_state.active_chat_id)

    # -----------------------------------------------------------------
    # CABE√áALHO
    # -----------------------------------------------------------------
    st.markdown("<h1 class='main-header'>AI Agent Chat</h1>", unsafe_allow_html=True)
    st.markdown(
        "<p style='text-align: center; color: gray;'>"
        "Trilha Master GenAI ‚Ä¢ 2026"
        "</p>",
        unsafe_allow_html=True
    )

    # -----------------------------------------------------------------
    # SIDEBAR
    # -----------------------------------------------------------------
    config = display_sidebar()

    # -----------------------------------------------------------------
    # CRIAR/ATUALIZAR AGENTE
    # -----------------------------------------------------------------
    # Verifica se precisa criar um novo agente
    # Isso acontece quando:
    # 1. N√£o existe agente ainda
    # 2. O tipo de agente mudou (ex: OpenAI -> Gemini)
    # 3. O modelo mudou (ex: gpt-4 -> gpt-4o)
    need_new_agent = (
        st.session_state.agent is None or
        st.session_state.current_agent_name != config["agent_name"] or
        st.session_state.current_model != config["model"]
    )

    if need_new_agent:
        with st.spinner("üîÑ Inicializando agente..."):
            agent = create_agent(
                agent_name=config["agent_name"],
                model=config["model"],
                temperature=config["temperature"],
                system_prompt=config["system_prompt"],
                guardrails=config["guardrails"],
                max_tokens=config["max_tokens"],
                top_p=config["top_p"],
                presence_penalty=config["presence_penalty"],
                frequency_penalty=config["frequency_penalty"],
                top_k=config["top_k"],
                vector_store_manager=st.session_state.vector_store_manager,
                # Par√¢metros de mem√≥ria
                memory_type=config["memory_type"],
                memory_max_messages=config["memory_max_messages"],
                memory_storage_path=config["memory_storage_path"],
                memory_session_id=config["memory_session_id"]
            )
            if agent:
                st.session_state.agent = agent
                st.session_state.current_agent_name = config["agent_name"]
                st.session_state.current_model = config["model"]  # Atualiza o modelo atual
                # Salva a configura√ß√£o no chat ativo
                sync_active_chat(config)
                st.toast(f"Agente {config['agent_name']} ({config['model']}) ativado!", icon="‚úÖ")

    agent = st.session_state.agent

    # -----------------------------------------------------------------
    # STATUS DO AGENTE
    # -----------------------------------------------------------------
    if agent:
        # Status b√°sico
        status_msg = f"Agente: **{config['agent_name']}** | Modelo: **{config['model']}**"

        # Adiciona status do RAG se habilitado
        if st.session_state.vector_store_manager is not None:
            num_docs = len(st.session_state.rag_documents)
            status_msg += f" | üìö RAG: **{num_docs} doc(s)**"

        st.success(status_msg)
        display_agent_info(agent)
    else:
        st.warning(
            f"‚ö†Ô∏è Configure a API Key para usar o {config['agent_name']}. "
            f"Veja a sidebar √† esquerda."
        )

    st.divider()

    # -----------------------------------------------------------------
    # HIST√ìRICO DE MENSAGENS
    # -----------------------------------------------------------------
    # Se n√£o h√° mensagens, mostra a mensagem de boas-vindas
    if not st.session_state.messages and config["welcome_message"].strip():
        with st.chat_message("assistant"):
            st.markdown(config["welcome_message"])

    # Exibe todas as mensagens anteriores
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # -----------------------------------------------------------------
    # INPUT DO USU√ÅRIO
    # -----------------------------------------------------------------
    if prompt := st.chat_input("Digite sua mensagem aqui..."):
        # Verifica se o agente est√° configurado
        if not agent:
            st.error("‚ùå Configure a API Key primeiro!")
            return

        # Adiciona mensagem do usu√°rio ao hist√≥rico
        st.session_state.messages.append({
            "role": "user",
            "content": prompt
        })

        # Exibe mensagem do usu√°rio
        with st.chat_message("user"):
            st.markdown(prompt)

        # Processa e exibe resposta do agente
        with st.chat_message("assistant"):
            with st.spinner("ü§î Pensando..."):
                response = agent.process_message(prompt)
                st.markdown(response)

        # Adiciona resposta ao hist√≥rico
        st.session_state.messages.append({
            "role": "assistant",
            "content": response
        })

        # Sincroniza o chat ativo com a configura√ß√£o atual
        sync_active_chat(config)


# =============================================================================
# PONTO DE ENTRADA
# =============================================================================
if __name__ == "__main__":
    main()
